{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\da01002\\anaconda3\\envs\\program\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\da01002\\anaconda3\\envs\\program\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\da01002\\anaconda3\\envs\\program\\lib\\site-packages (from beautifulsoup4->bs4) (2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\da01002\\anaconda3\\envs\\program\\lib\\site-packages (2.25.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\da01002\\anaconda3\\envs\\program\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\da01002\\anaconda3\\envs\\program\\lib\\site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\da01002\\anaconda3\\envs\\program\\lib\\site-packages (from requests) (1.26.2)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\da01002\\anaconda3\\envs\\program\\lib\\site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\da01002\\anaconda3\\envs\\program\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\da01002\\anaconda3\\envs\\program\\lib\\site-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\da01002\\anaconda3\\envs\\program\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\da01002\\anaconda3\\envs\\program\\lib\\site-packages (from pandas) (2020.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\da01002\\appdata\\roaming\\python\\python38\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Requirement already satisfied: lxml in c:\\users\\da01002\\anaconda3\\envs\\program\\lib\\site-packages (4.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests\n",
    "!pip install pandas\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>User_cm</th>\n",
       "      <th>UserUrl</th>\n",
       "      <th>BrandNameList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WEAR Official</td>\n",
       "      <td>WOMEN</td>\n",
       "      <td>https://wear.tw/wearofficial/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>高橋愛</td>\n",
       "      <td>154cm</td>\n",
       "      <td>https://wear.tw/takahashiai/</td>\n",
       "      <td>[UNIQLO, H&amp;M, American Apparel, haco!, Dr.Mart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kumika☆</td>\n",
       "      <td>158cm</td>\n",
       "      <td>https://wear.tw/ass03/</td>\n",
       "      <td>[TODAYFUL, ZARA, UNIQLO, via j, CANAL JEAN, BE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>橋下美好</td>\n",
       "      <td>160cm</td>\n",
       "      <td>https://wear.tw/miyoshi0511/</td>\n",
       "      <td>[UNIQLO, 無印良品, CONVERSE, Dr.Martens, niko and....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>えだ( ¨̮ )</td>\n",
       "      <td>155cm</td>\n",
       "      <td>https://wear.tw/unitarosu9876/</td>\n",
       "      <td>[Kastane, CONVERSE, GRL, GU, who's who Chico, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>てら</td>\n",
       "      <td>161cm</td>\n",
       "      <td>https://wear.tw/tera1008/</td>\n",
       "      <td>[GU, CONVERSE, UNIQLO, ROPE' PICNIC, LOWRYS FA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>anmi</td>\n",
       "      <td>156cm</td>\n",
       "      <td>https://wear.tw/an3chan/</td>\n",
       "      <td>[しまむら, GU, CONVERSE, DHOLIC, ap retro, CLEA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>HAREアトレ川崎｜yuria</td>\n",
       "      <td>168cm</td>\n",
       "      <td>https://wear.tw/yuriaaa5/</td>\n",
       "      <td>[HARE, UNIQLO, MOUSSY, Dr.Martens, KEEN, niko ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>だぶる</td>\n",
       "      <td>160cm</td>\n",
       "      <td>https://wear.tw/waaaaamm/</td>\n",
       "      <td>[GU, CONVERSE, UNIQLO, Lavish Gate, LOWRYS FAR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>村瀬紗英</td>\n",
       "      <td>159cm</td>\n",
       "      <td>https://wear.tw/murasesae/</td>\n",
       "      <td>[ANDGEEBEE, EMODA, SNIDEL, Lily Brown, MURUA, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            UserName User_cm                         UserUrl  \\\n",
       "0      WEAR Official   WOMEN   https://wear.tw/wearofficial/   \n",
       "1                高橋愛   154cm    https://wear.tw/takahashiai/   \n",
       "2            Kumika☆   158cm          https://wear.tw/ass03/   \n",
       "3               橋下美好   160cm    https://wear.tw/miyoshi0511/   \n",
       "4           えだ( ¨̮ )   155cm  https://wear.tw/unitarosu9876/   \n",
       "..               ...     ...                             ...   \n",
       "95                てら   161cm       https://wear.tw/tera1008/   \n",
       "96              anmi   156cm        https://wear.tw/an3chan/   \n",
       "97  HAREアトレ川崎｜yuria    168cm       https://wear.tw/yuriaaa5/   \n",
       "98               だぶる   160cm       https://wear.tw/waaaaamm/   \n",
       "99              村瀬紗英   159cm      https://wear.tw/murasesae/   \n",
       "\n",
       "                                        BrandNameList  \n",
       "0                                                   0  \n",
       "1   [UNIQLO, H&M, American Apparel, haco!, Dr.Mart...  \n",
       "2   [TODAYFUL, ZARA, UNIQLO, via j, CANAL JEAN, BE...  \n",
       "3   [UNIQLO, 無印良品, CONVERSE, Dr.Martens, niko and....  \n",
       "4   [Kastane, CONVERSE, GRL, GU, who's who Chico, ...  \n",
       "..                                                ...  \n",
       "95  [GU, CONVERSE, UNIQLO, ROPE' PICNIC, LOWRYS FA...  \n",
       "96       [しまむら, GU, CONVERSE, DHOLIC, ap retro, CLEA]  \n",
       "97  [HARE, UNIQLO, MOUSSY, Dr.Martens, KEEN, niko ...  \n",
       "98  [GU, CONVERSE, UNIQLO, Lavish Gate, LOWRYS FAR...  \n",
       "99  [ANDGEEBEE, EMODA, SNIDEL, Lily Brown, MURUA, ...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "url=\"https://wear.tw/women-ranking/user/\"\n",
    "userAgent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"\n",
    "headers={\n",
    "    \"User-Agent\" :userAgent\n",
    "}\n",
    "\n",
    "res = requests.get(url, headers=headers)\n",
    "\n",
    "# 以 Beautiful Soup 解析 HTML 程式碼\n",
    "soup=BeautifulSoup(res.text, 'html.parser')\n",
    "\n",
    "#usernames = soup.select('ol.clearfix li.first-line-item')\n",
    "usernames = soup.findAll('li',class_= lambda value: value in ['first-line-item' , 'other-line-item'])\n",
    "user_ls=list()\n",
    "for nameTag in usernames:\n",
    "    user_dict=dict() #字典\n",
    "    \n",
    "    UserName = nameTag.select('img')[0]['alt']\n",
    "    user_dict['UserName'] = UserName #print(UserName)\n",
    "    \n",
    "    cm = nameTag.select('ul.info.clearfix li')[0].text\n",
    "    user_dict['User_cm'] = cm  #print(cm)\n",
    "    \n",
    "    UserUrl = \"https://wear.tw\" + nameTag.select('a')[0]['href']\n",
    "    user_dict['UserUrl'] = UserUrl #print(UserUrl)\n",
    "    \n",
    "    res_user = requests.get(UserUrl, headers=headers)\n",
    "    soup=BeautifulSoup(res_user.text, 'html.parser')\n",
    "####################################################################    \n",
    "    brandname = soup.select('div.container.link_list ul.clearfix')\n",
    "    BrandNameList=list()\n",
    "    for brandtag in brandname:\n",
    "        BrandName = brandtag.select('a') #建立經常使用的品牌清單\n",
    "        for i in BrandName:\n",
    "            BrandNameList.append(i.text)\n",
    "            user_dict['BrandNameList']=BrandNameList #品牌列表\n",
    "####################################################################\n",
    "    user_menu = soup.select('div.user_menu div.main ul.clearfix')\n",
    "    UserMenuList=list()\n",
    "    for menu in user_menu:\n",
    "        usermenu = menu.select('li')\n",
    "        UserMenuList.append(menu.text)\n",
    "        user_dict['UserMenuList']= UserMenuList\n",
    "    user_ls.append(user_dict)\n",
    "\n",
    "df = pd.DataFrame.from_records(user_ls)\n",
    "df = df.fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('前100名使用者WOMEN.csv',encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-10-ae84cbd28ea0>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-ae84cbd28ea0>\"\u001b[1;36m, line \u001b[1;32m28\u001b[0m\n\u001b[1;33m    #         file.write(img.content)  # 寫入圖片的二進位碼\u001b[0m\n\u001b[1;37m                                                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
